{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89efcece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68262fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1930s  1970s  1980s    80s  absurd  action  action packed  adaptation  \\\n",
      "0  False  False  False  False   False   False          False       False   \n",
      "1  False  False  False  False   False   False          False       False   \n",
      "2  False  False  False  False   False   False          False       False   \n",
      "3  False  False  False  False   False   False          False       False   \n",
      "4  False  False  False  False   False   False          False       False   \n",
      "\n",
      "   adapted from:book  adolescence  ...  visuals    war  wartime  weapons  \\\n",
      "0              False        False  ...    False  False    False    False   \n",
      "1              False        False  ...    False  False    False    False   \n",
      "2              False        False  ...    False  False    False    False   \n",
      "3              False        False  ...    False  False    False    False   \n",
      "4              False        False  ...    False  False    False    False   \n",
      "\n",
      "   weird  whimsical  witty  women  world politics  writers  \n",
      "0  False      False  False  False           False    False  \n",
      "1  False      False  False  False           False    False  \n",
      "2  False      False  False  False           False    False  \n",
      "3  False      False  False   True           False    False  \n",
      "4  False      False  False  False           False    False  \n",
      "\n",
      "[5 rows x 450 columns]\n",
      "Total tags (columns): 450\n"
     ]
    }
   ],
   "source": [
    "df_transactions = pd.read_csv('datasets/transactions.csv')\n",
    "df_transactions['tags'] = df_transactions['tags'].apply(ast.literal_eval)\n",
    "\n",
    "transactions = df_transactions['tags'].tolist()\n",
    "\n",
    "te = TransactionEncoder()\n",
    "df_onehot = pd.DataFrame(\n",
    "    te.fit(transactions).transform(transactions),\n",
    "    columns=te.columns_\n",
    ")\n",
    "\n",
    "\n",
    "print(df_onehot.head())\n",
    "print(\"Total tags (columns):\", df_onehot.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b78bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining frequent itemsets...\n",
      "Processing 69081 combinations | Sampling itemset size 32\n",
      "‚úì Found 824 frequent itemsets in 7.24s\n",
      "\n",
      "Generating association rules...\n",
      "‚úì Generated 916 rules in 0.01s\n",
      "\n",
      "Rules by confidence range:\n",
      "  0.3-0.4: 246\n",
      "  0.4-0.5: 167\n",
      "  0.5-0.6: 120\n",
      "  0.6-0.7: 120\n",
      "  0.7+:    263\n",
      "\n",
      "Top 10 rules by confidence:\n",
      "                        antecedents   consequents  confidence   support  \\\n",
      "384   (action packed, fight scenes)      (action)    1.000000  0.016798   \n",
      "0                   (action packed)      (action)    0.997442  0.028238   \n",
      "380          (chase, action packed)      (action)    0.996063  0.018319   \n",
      "469  (computer animation, animated)   (animation)    0.993007  0.010282   \n",
      "721            (teen, girlie movie)  (teen movie)    0.993007  0.010282   \n",
      "463             (cartoon, animated)   (animation)    0.991667  0.017233   \n",
      "38                       (animated)   (animation)    0.981873  0.023532   \n",
      "594              (splatter, creepy)      (horror)    0.979310  0.010282   \n",
      "894                (teen, teenager)  (teen movie)    0.977612  0.018970   \n",
      "756         (teenager, high school)  (teen movie)    0.977143  0.012381   \n",
      "\n",
      "          lift  \n",
      "384  10.103146  \n",
      "0    10.077306  \n",
      "380  10.063369  \n",
      "469  22.048906  \n",
      "721  17.057736  \n",
      "463  22.019145  \n",
      "38   21.801687  \n",
      "594  13.717297  \n",
      "894  16.793282  \n",
      "756  16.785224  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Mining frequent itemsets...\")\n",
    "start = time.time()\n",
    "\n",
    "frequent_itemsets = apriori(\n",
    "    df_onehot,\n",
    "    min_support=0.01,     # ~138 movies\n",
    "    max_len=3,\n",
    "    use_colnames=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"‚úì Found {len(frequent_itemsets)} frequent itemsets in {elapsed:.2f}s\")\n",
    "\n",
    "print(\"\\nGenerating association rules...\")\n",
    "start = time.time()\n",
    "\n",
    "rules = association_rules(\n",
    "    frequent_itemsets,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=0.3  # Lower threshold to get more rules\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"‚úì Generated {len(rules)} rules in {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"\\nRules by confidence range:\")\n",
    "print(f\"  0.3-0.4: {len(rules[(rules['confidence'] >= 0.3) & (rules['confidence'] < 0.4)])}\")\n",
    "print(f\"  0.4-0.5: {len(rules[(rules['confidence'] >= 0.4) & (rules['confidence'] < 0.5)])}\")\n",
    "print(f\"  0.5-0.6: {len(rules[(rules['confidence'] >= 0.5) & (rules['confidence'] < 0.6)])}\")\n",
    "print(f\"  0.6-0.7: {len(rules[(rules['confidence'] >= 0.6) & (rules['confidence'] < 0.7)])}\")\n",
    "print(f\"  0.7+:    {len(rules[rules['confidence'] >= 0.7])}\")\n",
    "\n",
    "print(f\"\\nTop 10 rules by confidence:\")\n",
    "print(rules.nlargest(10, 'confidence')[['antecedents', 'consequents', 'confidence', 'support', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673eda66",
   "metadata": {},
   "source": [
    "## Objective 1: Binary Transactional Format\n",
    "\n",
    "The continuous relevance scores (0-1) have been transformed into binary transactions:\n",
    "- **Method**: Select top N tags per movie based on relevance threshold (0.4-1.0)\n",
    "- **Result**: Each movie ‚Üí list of present tags (binary: present=1, absent=0)\n",
    "- **One-hot encoding**: TransactionEncoder creates the binary matrix for Apriori\n",
    "\n",
    "This enables pattern mining on semantic relationships rather than just popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411f073",
   "metadata": {},
   "source": [
    "## Objective 2: High-Confidence & High-Lift Rule Analysis\n",
    "\n",
    "Find semantic relationships between descriptive tags (e.g., \"Tarantino-esque\" ‚Üí \"non-linear timeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f3173bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules with confidence >= 0.7: 263\n",
      "Rules with lift >= 2.0: 907\n",
      "Rules with BOTH: 263\n",
      "\n",
      "=== Top 10 Most Surprising Relationships (by Lift) ===\n",
      "\n",
      "IF [french]\n",
      "THEN [france]\n",
      "  Confidence: 73.08% | Lift: 42.05 | Support: 1.24%\n",
      "\n",
      "IF [france]\n",
      "THEN [french]\n",
      "  Confidence: 71.25% | Lift: 42.05 | Support: 1.24%\n",
      "\n",
      "IF [biopic]\n",
      "THEN [biography]\n",
      "  Confidence: 56.84% | Lift: 36.86 | Support: 1.17%\n",
      "\n",
      "IF [biography]\n",
      "THEN [biopic]\n",
      "  Confidence: 76.06% | Lift: 36.86 | Support: 1.17%\n",
      "\n",
      "IF [gay]\n",
      "THEN [gay character]\n",
      "  Confidence: 56.88% | Lift: 35.54 | Support: 1.11%\n",
      "\n",
      "IF [gay character]\n",
      "THEN [gay]\n",
      "  Confidence: 69.23% | Lift: 35.54 | Support: 1.11%\n",
      "\n",
      "IF [us history]\n",
      "THEN [history]\n",
      "  Confidence: 87.77% | Lift: 35.34 | Support: 1.19%\n",
      "\n",
      "IF [history]\n",
      "THEN [us history]\n",
      "  Confidence: 48.10% | Lift: 35.34 | Support: 1.19%\n",
      "\n",
      "IF [cartoon, animals]\n",
      "THEN [animated]\n",
      "  Confidence: 84.00% | Lift: 35.05 | Support: 1.06%\n",
      "\n",
      "IF [animated]\n",
      "THEN [cartoon, animals]\n",
      "  Confidence: 44.41% | Lift: 35.05 | Support: 1.06%\n",
      "\n",
      "\n",
      "=== Top 10 Most Reliable Relationships (by Confidence) ===\n",
      "\n",
      "IF [action packed, fight scenes]\n",
      "THEN [action]\n",
      "  Confidence: 100.00% | Lift: 10.10 | Support: 1.68%\n",
      "\n",
      "IF [action packed]\n",
      "THEN [action]\n",
      "  Confidence: 99.74% | Lift: 10.08 | Support: 2.82%\n",
      "\n",
      "IF [chase, action packed]\n",
      "THEN [action]\n",
      "  Confidence: 99.61% | Lift: 10.06 | Support: 1.83%\n",
      "\n",
      "IF [computer animation, animated]\n",
      "THEN [animation]\n",
      "  Confidence: 99.30% | Lift: 22.05 | Support: 1.03%\n",
      "\n",
      "IF [teen, girlie movie]\n",
      "THEN [teen movie]\n",
      "  Confidence: 99.30% | Lift: 17.06 | Support: 1.03%\n",
      "\n",
      "IF [cartoon, animated]\n",
      "THEN [animation]\n",
      "  Confidence: 99.17% | Lift: 22.02 | Support: 1.72%\n",
      "\n",
      "IF [animated]\n",
      "THEN [animation]\n",
      "  Confidence: 98.19% | Lift: 21.80 | Support: 2.35%\n",
      "\n",
      "IF [splatter, creepy]\n",
      "THEN [horror]\n",
      "  Confidence: 97.93% | Lift: 13.72 | Support: 1.03%\n",
      "\n",
      "IF [teen, teenager]\n",
      "THEN [teen movie]\n",
      "  Confidence: 97.76% | Lift: 16.79 | Support: 1.90%\n",
      "\n",
      "IF [teenager, high school]\n",
      "THEN [teen movie]\n",
      "  Confidence: 97.71% | Lift: 16.79 | Support: 1.24%\n"
     ]
    }
   ],
   "source": [
    "# Filter for high-quality rules\n",
    "high_confidence = rules[rules['confidence'] >= 0.7]\n",
    "high_lift = rules[rules['lift'] >= 2.0]\n",
    "quality_rules = rules[(rules['confidence'] >= 0.7) & (rules['lift'] >= 2.0)]\n",
    "\n",
    "print(f\"Rules with confidence >= 0.7: {len(high_confidence)}\")\n",
    "print(f\"Rules with lift >= 2.0: {len(high_lift)}\")\n",
    "print(f\"Rules with BOTH: {len(quality_rules)}\")\n",
    "\n",
    "# Show top semantic relationships by lift (surprising connections)\n",
    "print(\"\\n=== Top 10 Most Surprising Relationships (by Lift) ===\")\n",
    "top_lift = rules.nlargest(10, 'lift')[['antecedents', 'consequents', 'confidence', 'support', 'lift']]\n",
    "for idx, row in top_lift.iterrows():\n",
    "    ant = ', '.join(list(row['antecedents']))\n",
    "    con = ', '.join(list(row['consequents']))\n",
    "    print(f\"\\nIF [{ant}]\")\n",
    "    print(f\"THEN [{con}]\")\n",
    "    print(f\"  Confidence: {row['confidence']:.2%} | Lift: {row['lift']:.2f} | Support: {row['support']:.2%}\")\n",
    "\n",
    "# Show top by confidence (most reliable)\n",
    "print(\"\\n\\n=== Top 10 Most Reliable Relationships (by Confidence) ===\")\n",
    "top_conf = rules.nlargest(10, 'confidence')[['antecedents', 'consequents', 'confidence', 'support', 'lift']]\n",
    "for idx, row in top_conf.iterrows():\n",
    "    ant = ', '.join(list(row['antecedents']))\n",
    "    con = ', '.join(list(row['consequents']))\n",
    "    print(f\"\\nIF [{ant}]\")\n",
    "    print(f\"THEN [{con}]\")\n",
    "    print(f\"  Confidence: {row['confidence']:.2%} | Lift: {row['lift']:.2f} | Support: {row['support']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2345e",
   "metadata": {},
   "source": [
    "## Objective 3: Recommendation Diversity Demonstration\n",
    "\n",
    "Use association rules to recommend diverse films based on semantic trait linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f436557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed movie: Pulp Fiction (1994)\n",
      "Tags: masterpiece, gratuitous violence, dark humor, storytelling, violence, gangsters, stylish, violent, hit men, imdb top 250\n",
      "\n",
      "Applied 11 rules from seed tags\n",
      "Discovered 5 new related tags\n",
      "\n",
      "Top recommended tags (by aggregated score):\n",
      "  ‚Ä¢ brutality: 4 rules, avg lift=8.81, avg conf=0.45\n",
      "  ‚Ä¢ gangster: 1 rules, avg lift=26.61, avg conf=0.63\n",
      "  ‚Ä¢ crime: 1 rules, avg lift=9.36, avg conf=0.39\n",
      "  ‚Ä¢ oscar (best directing): 1 rules, avg lift=8.47, avg conf=0.41\n",
      "  ‚Ä¢ criterion: 1 rules, avg lift=4.95, avg conf=0.57\n",
      "\n",
      "=== Top 10 Diverse Recommendations ===\n",
      "\n",
      "1. Kiss of Death (1995)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "2. Truth or Consequences, N.M. (1997)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "3. General, The (1998)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "4. Chopper (2000)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "5. Across 110th Street (1972)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "6. Gangster No. 1 (2000)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "7. Love, Honour and Obey (2000)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "8. American Me (1992)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "9. Bullet (1996)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n",
      "\n",
      "10. Valachi Papers,The (1972)\n",
      "   Score: 71.22 (3 matching tags)\n",
      "   Via tags: brutality, crime, gangster\n"
     ]
    }
   ],
   "source": [
    "def recommend_by_rules(movie_title, rules_df, transactions_df, top_n=10, min_confidence=0.6):\n",
    "    \"\"\"\n",
    "    Recommend movies based on association rules from a seed movie's tags\n",
    "    \"\"\"\n",
    "    # Get seed movie tags\n",
    "    seed_movie = transactions_df[transactions_df['title'] == movie_title]\n",
    "    if seed_movie.empty:\n",
    "        print(f\"Movie '{movie_title}' not found\")\n",
    "        return None\n",
    "    \n",
    "    seed_tags = set(seed_movie.iloc[0]['tags'])\n",
    "    print(f\"Seed movie: {movie_title}\")\n",
    "    print(f\"Tags: {', '.join(list(seed_tags)[:10])}\\n\")\n",
    "    \n",
    "    # Filter rules by minimum confidence\n",
    "    filtered_rules = rules_df[rules_df['confidence'] >= min_confidence]\n",
    "    \n",
    "    # Find rules where antecedents are in seed tags\n",
    "    # Aggregate all rules for each tag (don't just keep the best)\n",
    "    recommended_tags = {}  # tag -> {'lifts': [], 'confidences': [], 'count': n}\n",
    "    rule_count = 0\n",
    "    \n",
    "    for _, rule in filtered_rules.iterrows():\n",
    "        antecedents = set(rule['antecedents'])\n",
    "        consequents = set(rule['consequents'])\n",
    "        \n",
    "        # If seed movie has the antecedent tags, recommend movies with consequent tags\n",
    "        if antecedents.issubset(seed_tags):\n",
    "            rule_count += 1\n",
    "            for tag in consequents:\n",
    "                if tag not in seed_tags:  # Don't recommend tags already present\n",
    "                    if tag not in recommended_tags:\n",
    "                        recommended_tags[tag] = {'lifts': [], 'confidences': [], 'count': 0}\n",
    "                    recommended_tags[tag]['lifts'].append(rule['lift'])\n",
    "                    recommended_tags[tag]['confidences'].append(rule['confidence'])\n",
    "                    recommended_tags[tag]['count'] += 1\n",
    "    \n",
    "    print(f\"Applied {rule_count} rules from seed tags\")\n",
    "    print(f\"Discovered {len(recommended_tags)} new related tags\\n\")\n",
    "    \n",
    "    if len(recommended_tags) == 0:\n",
    "        print(\"‚ö†Ô∏è  No rules found. Try lowering min_confidence or use more rules.\")\n",
    "        return []\n",
    "    \n",
    "    # Calculate aggregate scores for each tag\n",
    "    tag_scores = {}\n",
    "    for tag, stats in recommended_tags.items():\n",
    "        avg_lift = sum(stats['lifts']) / len(stats['lifts'])\n",
    "        avg_conf = sum(stats['confidences']) / len(stats['confidences'])\n",
    "        # Combined score: average lift * rule count (tags appearing in more rules rank higher)\n",
    "        tag_scores[tag] = (avg_lift * stats['count'], avg_conf, avg_lift, stats['count'])\n",
    "    \n",
    "    # Show top recommended tags\n",
    "    top_rec_tags = sorted(tag_scores.items(), key=lambda x: x[1][0], reverse=True)[:10]\n",
    "    print(\"Top recommended tags (by aggregated score):\")\n",
    "    for tag, (score, avg_conf, avg_lift, count) in top_rec_tags:\n",
    "        print(f\"  ‚Ä¢ {tag}: {count} rules, avg lift={avg_lift:.2f}, avg conf={avg_conf:.2f}\")\n",
    "    \n",
    "    # Find movies with recommended tags (excluding seed movie)\n",
    "    candidates = []\n",
    "    recommended_tag_set = set(recommended_tags.keys())\n",
    "    \n",
    "    for _, movie in transactions_df.iterrows():\n",
    "        if movie['title'] == movie_title:\n",
    "            continue\n",
    "        \n",
    "        movie_tags = set(movie['tags'])\n",
    "        overlap = recommended_tag_set.intersection(movie_tags)\n",
    "        \n",
    "        if overlap:\n",
    "            # Score by sum of aggregated tag scores\n",
    "            score = sum(tag_scores[tag][0] for tag in overlap)\n",
    "            candidates.append({\n",
    "                'title': movie['title'],\n",
    "                'score': score,\n",
    "                'matching_tags': overlap,\n",
    "                'tag_count': len(overlap)\n",
    "            })\n",
    "    \n",
    "    # Sort by score\n",
    "    candidates.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(f\"\\n=== Top {top_n} Diverse Recommendations ===\")\n",
    "    for i, rec in enumerate(candidates[:top_n], 1):\n",
    "        print(f\"\\n{i}. {rec['title']}\")\n",
    "        print(f\"   Score: {rec['score']:.2f} ({rec['tag_count']} matching tags)\")\n",
    "        print(f\"   Via tags: {', '.join(list(rec['matching_tags'])[:5])}\")\n",
    "    \n",
    "    return candidates[:top_n]\n",
    "\n",
    "\n",
    "example_movie = \"Pulp Fiction (1994)\"  \n",
    "recommendations = recommend_by_rules(example_movie, rules, df_transactions, top_n=10, min_confidence=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09875123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON: Rule-Based vs Simple Overlap\n",
      "================================================================================\n",
      "\n",
      "### BASELINE: Simple Tag Overlap ###\n",
      "\n",
      "### RULE-BASED: Semantic Association Rules ###\n",
      "Movie 'The Matrix (1999)' not found\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate diversity: Compare rule-based vs simple tag overlap\n",
    "def simple_tag_overlap_recommendations(movie_title, transactions_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Baseline: Recommend by direct tag overlap (no rules)\n",
    "    \"\"\"\n",
    "    seed_movie = transactions_df[transactions_df['title'] == movie_title]\n",
    "    if seed_movie.empty:\n",
    "        return None\n",
    "    \n",
    "    seed_tags = set(seed_movie.iloc[0]['tags'])\n",
    "    \n",
    "    candidates = []\n",
    "    for _, movie in transactions_df.iterrows():\n",
    "        if movie['title'] == movie_title:\n",
    "            continue\n",
    "        \n",
    "        movie_tags = set(movie['tags'])\n",
    "        overlap = seed_tags.intersection(movie_tags)\n",
    "        \n",
    "        if overlap:\n",
    "            candidates.append({\n",
    "                'title': movie['title'],\n",
    "                'score': len(overlap),\n",
    "                'matching_tags': overlap\n",
    "            })\n",
    "    \n",
    "    candidates.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return candidates[:top_n]\n",
    "\n",
    "# Compare approaches\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARISON: Rule-Based vs Simple Overlap\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_movie = \"Pulp Fiction (1994)\"  # Choose a well-known movie\n",
    "\n",
    "print(\"\\n### BASELINE: Simple Tag Overlap ###\")\n",
    "baseline_recs = simple_tag_overlap_recommendations(test_movie, df_transactions, top_n=5)\n",
    "if baseline_recs:\n",
    "    print(f\"Seed: {test_movie}\")\n",
    "    for i, rec in enumerate(baseline_recs, 1):\n",
    "        print(f\"{i}. {rec['title']} (overlap: {rec['score']})\")\n",
    "\n",
    "print(\"\\n### RULE-BASED: Semantic Association Rules ###\")\n",
    "rule_recs = recommend_by_rules(test_movie, rules, df_transactions, top_n=5, min_confidence=0.6)\n",
    "\n",
    "# Calculate diversity: unique movies between approaches\n",
    "if baseline_recs and rule_recs:\n",
    "    baseline_titles = {r['title'] for r in baseline_recs}\n",
    "    rule_titles = {r['title'] for r in rule_recs}\n",
    "    unique_rule = rule_titles - baseline_titles\n",
    "    \n",
    "    print(f\"\\nüéØ Diversity Gain: {len(unique_rule)}/{len(rule_recs)} recommendations are NEW (not in baseline)\")\n",
    "    if unique_rule:\n",
    "        print(f\"   Unique discoveries: {', '.join(list(unique_rule)[:3])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
